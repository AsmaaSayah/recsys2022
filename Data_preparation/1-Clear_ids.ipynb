{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4797/1135118813.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "base_path = '../dataset'\n",
    "\n",
    "original_data = os.path.join(base_path, 'original_data')\n",
    "processed_data = os.path.join(base_path, 'processed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [19],\n",
       "       [20]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_items=pd.read_csv(os.path.join(original_data, \"candidate_items.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "candidate_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/original_data/train_sessions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bexpert-space-carnival-v449xg4g5692p77j/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_sessions_items\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(original_data,\u001b[39m\"\u001b[39;49m\u001b[39mtrain_sessions.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m),usecols\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mitem_id\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mdrop_duplicates()\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mitem_id\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bexpert-space-carnival-v449xg4g5692p77j/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train_sessions_items[:\u001b[39m5\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1879\u001b[0m     f,\n\u001b[1;32m   1880\u001b[0m     mode,\n\u001b[1;32m   1881\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1882\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1883\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1885\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1886\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1887\u001b[0m )\n\u001b[1;32m   1888\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/original_data/train_sessions.csv'"
     ]
    }
   ],
   "source": [
    "train_sessions_items=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "train_sessions_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_purchases_items=pd.read_csv(os.path.join(original_data,\"train_purchases.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "train_purchases_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3],\n",
       "       [ 4],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sessions_items=pd.read_csv(os.path.join(original_data,\"test_final_sessions.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "test_sessions_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [19],\n",
       "       [20]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sessions_leaderboard_items=pd.read_csv(os.path.join(original_data,\"test_leaderboard_sessions.csv\"),usecols=[\"item_id\"]).drop_duplicates().sort_values(by=\"item_id\").to_numpy()\n",
    "test_sessions_leaderboard_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_test_items = np.concatenate((test_sessions_leaderboard_items, test_sessions_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  313,   366,   575,  1152,  1364,  1883,  2497,  2523,  2677,\n",
       "        2694,  3185,  3529,  3754,  3835,  4042,  4514,  5214,  5394,\n",
       "        6171,  6853,  6873,  6916,  7204,  7780,  8758,  8771,  9384,\n",
       "        9418,  9589, 10463, 10671, 11125, 11933, 12667, 13376, 13618,\n",
       "       13943, 13972, 14395, 14622, 14723, 14967, 15601, 15629, 16206,\n",
       "       17046, 17206, 18482, 18690, 18837, 19637, 19808, 21241, 21444,\n",
       "       21904, 21927, 21998, 22030, 22316, 22703, 22746, 24165, 24303,\n",
       "       25035, 25277, 25521, 26232, 26742, 27377, 27728, 27826])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InTestButNotInTrain=np.setdiff1d(total_test_items,train_sessions_items)\n",
    "InTestButNotInTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71  items are in test sessions but not in train\n"
     ]
    }
   ],
   "source": [
    "print(len(InTestButNotInTrain),\" items are in test sessions but not in train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(InTestButNotInTrain,train_purchases_items)\n",
    "#None of those 67 items is seen in the train_purchases, so they are unknown items, should be treated in a special way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  221,   313,   344,   366,   575,   950,  1152,  1222,  1364,\n",
       "        1883,  1935,  2411,  2489,  2497,  2523,  2621,  2677,  2694,\n",
       "        3185,  3220,  3529,  3754,  3835,  4042,  4514,  6171,  6425,\n",
       "        6512,  6853,  6873,  6916,  7204,  7321,  7408,  7710,  7780,\n",
       "        8053,  8758,  8814,  8839,  8928,  9384,  9418,  9589,  9974,\n",
       "       10463, 10491, 10496, 10671, 10694, 11125, 11862, 11933, 12438,\n",
       "       12641, 12667, 13376, 13550, 13618, 13788, 13943, 13972, 14167,\n",
       "       14395, 14535, 14723, 15629, 15719, 16045, 16092, 16206, 16800,\n",
       "       17046, 17057, 17206, 17371, 17534, 17576, 17950, 18837, 19808,\n",
       "       20237, 21056, 21241, 21444, 21599, 21904, 21998, 22096, 22143,\n",
       "       22316, 22583, 22703, 22746, 22838, 23640, 23981, 24239, 24303,\n",
       "       25035, 25179, 25277, 25298, 25521, 26201, 26232, 26742, 27042,\n",
       "       27377, 27427, 27728, 27826, 27847])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CandidateNeverBoughtInTrainingSet=np.setdiff1d(candidate_items,train_purchases_items)\n",
    "CandidateNeverBoughtInTrainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CandidateNeverBoughtInTrainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  221,   344,   950,  1222,  1935,  2411,  2489,  2621,  3220,\n",
       "        6425,  6512,  7321,  7408,  7710,  8053,  8839,  8928,  9974,\n",
       "       10491, 10496, 10694, 11862, 12438, 12641, 13550, 13788, 14167,\n",
       "       14535, 15719, 16045, 16092, 16800, 17057, 17371, 17534, 17950,\n",
       "       21056, 21599, 22096, 22143, 22583, 22838, 23640, 23981, 24239,\n",
       "       25179, 25298, 27042, 27427, 27847])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SeenInTrainSessions=np.intersect1d(CandidateNeverBoughtInTrainingSet,train_sessions_items)\n",
    "SeenInTrainSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SeenInTrainSessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data=np.concatenate((candidate_items,train_purchases_items,train_sessions_items,test_sessions_items,test_sessions_leaderboard_items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=[\"item_id\"],data=data,index=[i for i,_ in enumerate(data)]).drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22569 entries, 0 to 22568\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   index    22569 non-null  int64\n",
      " 1   item_id  22569 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 352.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"code\"]=df.index\n",
    "df[\"code\"]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FilePathOrBuffer' from 'pandas._typing' (/home/codespace/.local/lib/python3.10/site-packages/pandas/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bominous-space-capybara-566jw464rxw2vvwr/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(processed_data,\u001b[39m\"\u001b[39;49m\u001b[39mmap.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m),index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    326\u001b[0m kind \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mParameter\u001b[39m.\u001b[39mPOSITIONAL_OR_KEYWORD\n\u001b[1;32m    327\u001b[0m params \u001b[39m=\u001b[39m [\n\u001b[1;32m    328\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, kind),\n\u001b[1;32m    329\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(name, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    330\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    331\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    332\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39maxis\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[0;32m--> 333\u001b[0m ]\n\u001b[1;32m    335\u001b[0m \u001b[39mfor\u001b[39;00m pname, default \u001b[39min\u001b[39;00m extra_params:\n\u001b[1;32m    336\u001b[0m     params\u001b[39m.\u001b[39mappend(inspect\u001b[39m.\u001b[39mParameter(pname, kind, default\u001b[39m=\u001b[39mdefault))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3961\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3957\u001b[0m             del self[col]\n\u001b[1;32m   3958\u001b[0m             deleted = True\n\u001b[1;32m   3959\u001b[0m if not deleted:\n\u001b[1;32m   3960\u001b[0m     # If the above loop ran and didn't delete anything because\n\u001b[0;32m-> 3961\u001b[0m     # there was no match, this call should raise the appropriate\n\u001b[1;32m   3962\u001b[0m     # exception:\n\u001b[1;32m   3963\u001b[0m     loc = self.axes[-1].get_loc(key)\n\u001b[1;32m   3964\u001b[0m     self._mgr = self._mgr.idelete(loc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:987\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    980\u001b[0m     string \u001b[39m=\u001b[39m latex_formatter\u001b[39m.\u001b[39mto_string()\n\u001b[1;32m    981\u001b[0m     \u001b[39mreturn\u001b[39;00m save_to_buffer(string, buf\u001b[39m=\u001b[39mbuf, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[1;32m    983\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_html\u001b[39m(\n\u001b[1;32m    984\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    985\u001b[0m     buf: FilePathOrBuffer[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m     encoding: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m--> 987\u001b[0m     classes: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m \u001b[39m|\u001b[39m \u001b[39mtuple\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    988\u001b[0m     notebook: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    989\u001b[0m     border: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    990\u001b[0m     table_id: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    991\u001b[0m     render_links: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    992\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[39m    Render a DataFrame to a html table.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[39m        Convert URLs to HTML links.\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhtml\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m   1016\u001b[0m         HTMLFormatter,\n\u001b[1;32m   1017\u001b[0m         NotebookFormatter,\n\u001b[1;32m   1018\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m writers \u001b[39mas\u001b[39;00m libwriters\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     CompressionOptions,\n\u001b[1;32m     23\u001b[0m     FilePathOrBuffer,\n\u001b[1;32m     24\u001b[0m     FloatFormatType,\n\u001b[1;32m     25\u001b[0m     IndexLabel,\n\u001b[1;32m     26\u001b[0m     StorageOptions,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     ABCDatetimeIndex,\n\u001b[1;32m     31\u001b[0m     ABCIndex,\n\u001b[1;32m     32\u001b[0m     ABCMultiIndex,\n\u001b[1;32m     33\u001b[0m     ABCPeriodIndex,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmissing\u001b[39;00m \u001b[39mimport\u001b[39;00m notna\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FilePathOrBuffer' from 'pandas._typing' (/home/codespace/.local/lib/python3.10/site-packages/pandas/_typing.py)"
     ]
    }
   ],
   "source": [
    "df.to_csv(os.path.join(processed_data,\"map.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FilePathOrBuffer' from 'pandas._typing' (/home/codespace/.local/lib/python3.10/site-packages/pandas/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bominous-space-capybara-566jw464rxw2vvwr/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df[:\u001b[39m19021\u001b[39;49m]\u001b[39m.\u001b[39;49mto_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(processed_data,\u001b[39m\"\u001b[39;49m\u001b[39mmap_purchases.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m),index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m# Mapping of only bought items\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    326\u001b[0m kind \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mParameter\u001b[39m.\u001b[39mPOSITIONAL_OR_KEYWORD\n\u001b[1;32m    327\u001b[0m params \u001b[39m=\u001b[39m [\n\u001b[1;32m    328\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, kind),\n\u001b[1;32m    329\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(name, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    330\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    331\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    332\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39maxis\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[0;32m--> 333\u001b[0m ]\n\u001b[1;32m    335\u001b[0m \u001b[39mfor\u001b[39;00m pname, default \u001b[39min\u001b[39;00m extra_params:\n\u001b[1;32m    336\u001b[0m     params\u001b[39m.\u001b[39mappend(inspect\u001b[39m.\u001b[39mParameter(pname, kind, default\u001b[39m=\u001b[39mdefault))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3961\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3957\u001b[0m             del self[col]\n\u001b[1;32m   3958\u001b[0m             deleted = True\n\u001b[1;32m   3959\u001b[0m if not deleted:\n\u001b[1;32m   3960\u001b[0m     # If the above loop ran and didn't delete anything because\n\u001b[0;32m-> 3961\u001b[0m     # there was no match, this call should raise the appropriate\n\u001b[1;32m   3962\u001b[0m     # exception:\n\u001b[1;32m   3963\u001b[0m     loc = self.axes[-1].get_loc(key)\n\u001b[1;32m   3964\u001b[0m     self._mgr = self._mgr.idelete(loc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:987\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    980\u001b[0m     string \u001b[39m=\u001b[39m latex_formatter\u001b[39m.\u001b[39mto_string()\n\u001b[1;32m    981\u001b[0m     \u001b[39mreturn\u001b[39;00m save_to_buffer(string, buf\u001b[39m=\u001b[39mbuf, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[1;32m    983\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_html\u001b[39m(\n\u001b[1;32m    984\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    985\u001b[0m     buf: FilePathOrBuffer[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m     encoding: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m--> 987\u001b[0m     classes: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m \u001b[39m|\u001b[39m \u001b[39mtuple\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    988\u001b[0m     notebook: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    989\u001b[0m     border: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    990\u001b[0m     table_id: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    991\u001b[0m     render_links: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    992\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[39m    Render a DataFrame to a html table.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[39m        Convert URLs to HTML links.\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhtml\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m   1016\u001b[0m         HTMLFormatter,\n\u001b[1;32m   1017\u001b[0m         NotebookFormatter,\n\u001b[1;32m   1018\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m writers \u001b[39mas\u001b[39;00m libwriters\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     CompressionOptions,\n\u001b[1;32m     23\u001b[0m     FilePathOrBuffer,\n\u001b[1;32m     24\u001b[0m     FloatFormatType,\n\u001b[1;32m     25\u001b[0m     IndexLabel,\n\u001b[1;32m     26\u001b[0m     StorageOptions,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     ABCDatetimeIndex,\n\u001b[1;32m     31\u001b[0m     ABCIndex,\n\u001b[1;32m     32\u001b[0m     ABCMultiIndex,\n\u001b[1;32m     33\u001b[0m     ABCPeriodIndex,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmissing\u001b[39;00m \u001b[39mimport\u001b[39;00m notna\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FilePathOrBuffer' from 'pandas._typing' (/home/codespace/.local/lib/python3.10/site-packages/pandas/_typing.py)"
     ]
    }
   ],
   "source": [
    "df[:19021].to_csv(os.path.join(processed_data,\"map_purchases.csv\"),index=False) # Mapping of only bought items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4728/3866861342.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  train_sessions=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"),parse_dates=['date'],\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FilePathOrBuffer' from 'pandas._typing' (/home/codespace/.local/lib/python3.10/site-packages/pandas/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb Cell 22\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bominous-space-capybara-566jw464rxw2vvwr/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m train_sessions_ids\u001b[39m=\u001b[39mtrain_sessions_ids\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bominous-space-capybara-566jw464rxw2vvwr/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m train_sessions_ids[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39mtrain_sessions_ids\u001b[39m.\u001b[39mindex\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bominous-space-capybara-566jw464rxw2vvwr/workspaces/recsys2022/Data_preparation/1-Clear_ids.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m train_sessions_ids\u001b[39m.\u001b[39;49mto_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(processed_data,\u001b[39m\"\u001b[39;49m\u001b[39msessions_map.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m),index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    326\u001b[0m kind \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mParameter\u001b[39m.\u001b[39mPOSITIONAL_OR_KEYWORD\n\u001b[1;32m    327\u001b[0m params \u001b[39m=\u001b[39m [\n\u001b[1;32m    328\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, kind),\n\u001b[1;32m    329\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(name, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    330\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    331\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    332\u001b[0m     inspect\u001b[39m.\u001b[39mParameter(\u001b[39m\"\u001b[39m\u001b[39maxis\u001b[39m\u001b[39m\"\u001b[39m, kind, default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[0;32m--> 333\u001b[0m ]\n\u001b[1;32m    335\u001b[0m \u001b[39mfor\u001b[39;00m pname, default \u001b[39min\u001b[39;00m extra_params:\n\u001b[1;32m    336\u001b[0m     params\u001b[39m.\u001b[39mappend(inspect\u001b[39m.\u001b[39mParameter(pname, kind, default\u001b[39m=\u001b[39mdefault))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3961\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3957\u001b[0m             del self[col]\n\u001b[1;32m   3958\u001b[0m             deleted = True\n\u001b[1;32m   3959\u001b[0m if not deleted:\n\u001b[1;32m   3960\u001b[0m     # If the above loop ran and didn't delete anything because\n\u001b[0;32m-> 3961\u001b[0m     # there was no match, this call should raise the appropriate\n\u001b[1;32m   3962\u001b[0m     # exception:\n\u001b[1;32m   3963\u001b[0m     loc = self.axes[-1].get_loc(key)\n\u001b[1;32m   3964\u001b[0m     self._mgr = self._mgr.idelete(loc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:987\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    980\u001b[0m     string \u001b[39m=\u001b[39m latex_formatter\u001b[39m.\u001b[39mto_string()\n\u001b[1;32m    981\u001b[0m     \u001b[39mreturn\u001b[39;00m save_to_buffer(string, buf\u001b[39m=\u001b[39mbuf, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[1;32m    983\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_html\u001b[39m(\n\u001b[1;32m    984\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    985\u001b[0m     buf: FilePathOrBuffer[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m     encoding: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m--> 987\u001b[0m     classes: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m \u001b[39m|\u001b[39m \u001b[39mtuple\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    988\u001b[0m     notebook: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    989\u001b[0m     border: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    990\u001b[0m     table_id: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    991\u001b[0m     render_links: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    992\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[39m    Render a DataFrame to a html table.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[39m        Convert URLs to HTML links.\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhtml\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m   1016\u001b[0m         HTMLFormatter,\n\u001b[1;32m   1017\u001b[0m         NotebookFormatter,\n\u001b[1;32m   1018\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m writers \u001b[39mas\u001b[39;00m libwriters\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     CompressionOptions,\n\u001b[1;32m     23\u001b[0m     FilePathOrBuffer,\n\u001b[1;32m     24\u001b[0m     FloatFormatType,\n\u001b[1;32m     25\u001b[0m     IndexLabel,\n\u001b[1;32m     26\u001b[0m     StorageOptions,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     ABCDatetimeIndex,\n\u001b[1;32m     31\u001b[0m     ABCIndex,\n\u001b[1;32m     32\u001b[0m     ABCMultiIndex,\n\u001b[1;32m     33\u001b[0m     ABCPeriodIndex,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmissing\u001b[39;00m \u001b[39mimport\u001b[39;00m notna\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FilePathOrBuffer' from 'pandas._typing' (/home/codespace/.local/lib/python3.10/site-packages/pandas/_typing.py)"
     ]
    }
   ],
   "source": [
    "train_sessions=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"),parse_dates=['date'], \n",
    "                         infer_datetime_format=True,header=0)\n",
    "                         \n",
    "train_sessions_ids=train_sessions.sort_values(\"date\").drop_duplicates(\"session_id\",keep='first')[\"session_id\"]\n",
    "train_sessions_ids=train_sessions_ids.reset_index()\n",
    "train_sessions_ids[\"index\"]=train_sessions_ids.index\n",
    "train_sessions_ids.to_csv(os.path.join(processed_data,\"sessions_map.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_sessions=pd.read_csv(os.path.join(original_data,\"test_final_sessions.csv\"))\n",
    "test_leaderboard_sessions=pd.read_csv(os.path.join(original_data,\"test_leaderboard_sessions.csv\"))\n",
    "test_sessions=pd.concat([test_final_sessions,test_leaderboard_sessions],axis=0)\n",
    "\n",
    "test_sessions_ids=test_sessions.sort_values(\"date\").drop_duplicates(\"session_id\",keep='first')[\"session_id\"]\n",
    "test_sessions_ids=test_sessions_ids.reset_index()\n",
    "test_sessions_ids[\"index\"]=test_sessions_ids.index\n",
    "test_sessions_ids.to_csv(os.path.join(processed_data,\"test_sessions_map.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_items=pd.read_csv(os.path.join(original_data,\"candidate_items.csv\"))\n",
    "candidate_items=candidate_items.merge(df,on=\"item_id\",how=\"left\")\n",
    "candidate_items[\"item_id\"]=candidate_items[\"code\"]\n",
    "del candidate_items[\"code\"]\n",
    "candidate_items.to_csv(os.path.join(processed_data,\"candidate_items_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_sessions=pd.read_csv(os.path.join(original_data,\"test_final_sessions.csv\"))\n",
    "test_final_sessions=test_final_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "test_final_sessions[\"item_id\"]=test_final_sessions[\"code\"]\n",
    "del test_final_sessions[\"code\"]\n",
    "test_final_sessions=test_final_sessions.merge(test_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "test_final_sessions[\"session_id\"]=test_final_sessions[\"index\"]\n",
    "del test_final_sessions[\"index\"]\n",
    "test_final_sessions.to_csv(os.path.join(processed_data,\"test_final_sessions_full_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_sessions=pd.read_csv(os.path.join(original_data,\"test_final_sessions.csv\"))\n",
    "test_final_sessions=test_final_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "test_final_sessions[\"item_id\"]=test_final_sessions[\"code\"]\n",
    "del test_final_sessions[\"code\"]\n",
    "test_final_sessions.to_csv(os.path.join(processed_data,\"test_final_sessions_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leaderboard_sessions=pd.read_csv(os.path.join(original_data,\"test_leaderboard_sessions.csv\"))\n",
    "test_leaderboard_sessions=test_leaderboard_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "test_leaderboard_sessions[\"item_id\"]=test_leaderboard_sessions[\"code\"]\n",
    "del test_leaderboard_sessions[\"code\"]\n",
    "test_leaderboard_sessions=test_leaderboard_sessions.merge(test_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "test_leaderboard_sessions[\"session_id\"]=test_leaderboard_sessions[\"index\"]\n",
    "del test_leaderboard_sessions[\"index\"]\n",
    "test_leaderboard_sessions.to_csv(os.path.join(processed_data,\"test_leaderboard_sessions_full_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leaderboard_sessions=pd.read_csv(os.path.join(original_data,\"test_leaderboard_sessions.csv\"))\n",
    "test_leaderboard_sessions=test_leaderboard_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "test_leaderboard_sessions[\"item_id\"]=test_leaderboard_sessions[\"code\"]\n",
    "del test_leaderboard_sessions[\"code\"]\n",
    "test_leaderboard_sessions.to_csv(os.path.join(processed_data,\"test_leaderboard_sessions_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases=pd.read_csv(os.path.join(original_data,\"train_purchases.csv\"))\n",
    "train_purchases=train_purchases.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_purchases[\"item_id\"]=train_purchases[\"code\"]\n",
    "del train_purchases[\"code\"]\n",
    "train_purchases=train_purchases.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_purchases[\"session_id\"]=train_purchases[\"index\"]\n",
    "del train_purchases[\"index\"]\n",
    "train_purchases.to_csv(os.path.join(processed_data,\"train_purchases_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"))\n",
    "train_sessions=train_sessions.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_sessions[\"item_id\"]=train_sessions[\"code\"]\n",
    "del train_sessions[\"code\"]\n",
    "train_sessions=train_sessions.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_sessions[\"session_id\"]=train_sessions[\"index\"]\n",
    "del train_sessions[\"index\"]\n",
    "train_sessions.to_csv(os.path.join(processed_data,\"train_sessions_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item_features=pd.read_csv(os.path.join(original_data,\"item_features.csv\"))\n",
    "item_features=item_features.merge(df,on=\"item_id\",how=\"left\")\n",
    "item_features[\"item_id\"]=item_features[\"code\"]\n",
    "del item_features[\"code\"]\n",
    "item_features.to_csv(os.path.join(processed_data,\"item_features_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions=pd.read_csv(os.path.join(original_data,\"train_sessions.csv\"),parse_dates=['date'], \n",
    "                         infer_datetime_format=True,header=0)\n",
    "\n",
    "\n",
    "last_month_start = datetime.strptime(\"01/05/21 00:00:00\", '%d/%m/%y %H:%M:%S')\n",
    "\n",
    "train_sessions_train_split=train_sessions[train_sessions[\"date\"]<last_month_start]\n",
    "\n",
    "\n",
    "train_sessions_train_split=train_sessions_train_split.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_sessions_train_split[\"item_id\"]=train_sessions_train_split[\"code\"]\n",
    "del train_sessions_train_split[\"code\"]\n",
    "train_sessions_train_split=train_sessions_train_split.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_sessions_train_split[\"session_id\"]=train_sessions_train_split[\"index\"]\n",
    "del train_sessions_train_split[\"index\"]\n",
    "train_sessions_train_split.to_csv(os.path.join(processed_data,\"train_sessions_train_split_mapped.csv\"),index=False)\n",
    "\n",
    "train_sessions_valid_split=train_sessions[train_sessions[\"date\"]>=last_month_start]\n",
    "\n",
    "\n",
    "train_sessions_valid_split=train_sessions_valid_split.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_sessions_valid_split[\"item_id\"]=train_sessions_valid_split[\"code\"]\n",
    "del train_sessions_valid_split[\"code\"]\n",
    "train_sessions_valid_split=train_sessions_valid_split.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_sessions_valid_split[\"session_id\"]=train_sessions_valid_split[\"index\"]\n",
    "del train_sessions_valid_split[\"index\"]\n",
    "train_sessions_valid_split.to_csv(os.path.join(processed_data,\"train_sessions_valid_split_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases=pd.read_csv(os.path.join(original_data,\"train_purchases.csv\"),parse_dates=['date'], \n",
    "                         infer_datetime_format=True,header=0)\n",
    "\n",
    "\n",
    "last_month_start = datetime.strptime(\"01/05/21 00:00:00\", '%d/%m/%y %H:%M:%S')\n",
    "\n",
    "train_purchases_train_split=train_purchases[train_purchases[\"date\"]<last_month_start]\n",
    "\n",
    "\n",
    "train_purchases_train_split=train_purchases_train_split.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_purchases_train_split[\"item_id\"]=train_purchases_train_split[\"code\"]\n",
    "del train_purchases_train_split[\"code\"]\n",
    "train_purchases_train_split=train_purchases_train_split.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_purchases_train_split[\"session_id\"]=train_purchases_train_split[\"index\"]\n",
    "del train_purchases_train_split[\"index\"]\n",
    "train_purchases_train_split.to_csv(os.path.join(processed_data,\"train_purchases_train_split_mapped.csv\"),index=False)\n",
    "\n",
    "train_purchases_valid_split=train_purchases[train_purchases[\"date\"]>=last_month_start]\n",
    "\n",
    "\n",
    "train_purchases_valid_split=train_purchases_valid_split.merge(df,on=\"item_id\",how=\"left\")\n",
    "train_purchases_valid_split[\"item_id\"]=train_purchases_valid_split[\"code\"]\n",
    "del train_purchases_valid_split[\"code\"]\n",
    "train_purchases_valid_split=train_purchases_valid_split.merge(train_sessions_ids,on=\"session_id\",how=\"left\")\n",
    "train_purchases_valid_split[\"session_id\"]=train_purchases_valid_split[\"index\"]\n",
    "del train_purchases_valid_split[\"index\"]\n",
    "train_purchases_valid_split.to_csv(os.path.join(processed_data,\"train_purchases_valid_split_mapped.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    \n",
    "    \n",
    "    df_URM['count']=1\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)),shape=(1000000,23692))\n",
    "\n",
    "    \n",
    "\n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions_seen = get_URM()\n",
    "train_bought = get_URM(\"train_purchases_train_split_mapped.csv\")\n",
    "\n",
    "valid_sessions_seen= get_URM(\"train_sessions_valid_split_mapped.csv\")\n",
    "valid_bought = get_URM(\"train_purchases_valid_split_mapped.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.save_npz(os.path.join(processed_data, \"URM_train_seen.npz\"), train_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_train_bought.npz\"), train_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_valid_seen.npz\"), valid_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_valid_bought.npz\"), valid_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_train_full.npz\"), train_sessions_seen+train_bought)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_valid_full.npz\"), valid_sessions_seen+valid_bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM_test(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    \n",
    "    \n",
    "    df_URM['count']=1\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)))\n",
    "\n",
    "    \n",
    "\n",
    "    return URM,np.unique(session_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leaderboard,leaderboard_sessions = get_URM_test(file=\"test_leaderboard_sessions_mapped.csv\")\n",
    "\n",
    "test_final,final_sessions = get_URM_test(file=\"test_final_sessions_mapped.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.save_npz(os.path.join(processed_data, \"URM_test_leaderboard.npz\"), test_leaderboard)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_test_final.npz\"), test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(processed_data, \"leaderboard_sessions_ids\"),leaderboard_sessions)\n",
    "np.save(os.path.join(processed_data, \"final_sessions_ids\"),final_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM_temporal_decay(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False,temperature=30,last_date=datetime.strptime(\"01/05/21 00:00:00\", '%d/%m/%y %H:%M:%S')):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    df_URM[\"diff\"] = last_date-df_URM[\"date\"]\n",
    "    df_URM[\"days\"] = df_URM[\"diff\"].dt.days\n",
    "    df_URM[\"days\"] = df_URM[\"days\"].apply(lambda x: max(0,x))\n",
    "    df_URM[\"count\"] = df_URM[\"days\"].apply(lambda x: np.exp(-x/temperature))\n",
    "    print(df_URM.head(10))\n",
    "\n",
    "\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)),shape=(1000000,23692))\n",
    "\n",
    "    \n",
    "    print(\"computed\")\n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                    date                     diff  days  \\\n",
      "0      663204     9769 2020-12-18 21:25:00.373 133 days 02:34:59.627000   133   \n",
      "1      663204     9769 2020-12-18 21:19:48.093 133 days 02:40:11.907000   133   \n",
      "2       85375    12783 2020-03-13 19:35:27.136 413 days 04:24:32.864000   413   \n",
      "3      374472    14116 2020-08-26 19:18:30.833 247 days 04:41:29.167000   247   \n",
      "4      374472     6166 2020-08-26 19:16:31.211 247 days 04:43:28.789000   247   \n",
      "5      374472     6924 2020-08-26 19:15:47.232 247 days 04:44:12.768000   247   \n",
      "6      526578     4546 2020-11-02 16:31:18.543 179 days 07:28:41.457000   179   \n",
      "7      526578     8092 2020-11-02 16:34:33.794 179 days 07:25:26.206000   179   \n",
      "8      526578    17752 2020-11-02 16:43:04.022 179 days 07:16:55.978000   179   \n",
      "9      526578    14975 2020-11-02 16:42:02.287 179 days 07:17:57.713000   179   \n",
      "\n",
      "      count  \n",
      "0  0.011875  \n",
      "1  0.011875  \n",
      "2  0.000001  \n",
      "3  0.000266  \n",
      "4  0.000266  \n",
      "5  0.000266  \n",
      "6  0.002563  \n",
      "7  0.002563  \n",
      "8  0.002563  \n",
      "9  0.002563  \n",
      "computed\n",
      "   session_id  item_id                    date                     diff  days  \\\n",
      "0      663204    12492 2020-12-18 21:26:47.986 133 days 02:33:12.014000   133   \n",
      "1       85375     3299 2020-03-13 19:36:15.507 413 days 04:23:44.493000   413   \n",
      "2      374472    17411 2020-08-26 19:20:32.049 247 days 04:39:27.951000   247   \n",
      "3      526578    11229 2020-11-02 17:16:45.920 179 days 06:43:14.080000   179   \n",
      "4       66630    11568 2020-02-26 18:27:44.114 429 days 05:32:15.886000   429   \n",
      "5      192688    18172 2020-05-18 12:52:09.764 347 days 11:07:50.236000   347   \n",
      "6      895749     1512 2021-04-20 19:46:42.594  10 days 04:13:17.406000    10   \n",
      "7      257246    12205 2020-06-21 10:33:22.535 313 days 13:26:37.465000   313   \n",
      "8      789144     2124 2021-03-01 15:17:04.264  60 days 08:42:55.736000    60   \n",
      "9      580394     6925 2020-11-27 20:46:08.951 154 days 03:13:51.049000   154   \n",
      "\n",
      "          count  \n",
      "0  1.187484e-02  \n",
      "1  1.050056e-06  \n",
      "2  2.656494e-04  \n",
      "3  2.562770e-03  \n",
      "4  6.160116e-07  \n",
      "5  9.476773e-06  \n",
      "6  7.165313e-01  \n",
      "7  2.943479e-05  \n",
      "8  1.353353e-01  \n",
      "9  5.896871e-03  \n",
      "computed\n",
      "   session_id  item_id                    date                      diff  \\\n",
      "0      929236      417 2021-05-05 13:19:15.147  -5 days +10:40:44.853000   \n",
      "1      929236     3054 2021-05-05 14:13:21.645  -5 days +09:46:38.355000   \n",
      "2      929236     2780 2021-05-05 13:19:54.211  -5 days +10:40:05.789000   \n",
      "3      929236    14829 2021-05-05 13:18:49.495  -5 days +10:41:10.505000   \n",
      "4      929236     3746 2021-05-05 14:03:43.401  -5 days +09:56:16.599000   \n",
      "5      929236     1139 2021-05-05 13:18:20.994  -5 days +10:41:39.006000   \n",
      "6      984653     2950 2021-05-27 10:14:06.491 -27 days +13:45:53.509000   \n",
      "7      984653     3491 2021-05-27 10:14:01.136 -27 days +13:45:58.864000   \n",
      "8      984653     2821 2021-05-27 10:13:55.930 -27 days +13:46:04.070000   \n",
      "9      984653     3491 2021-05-27 10:13:40.996 -27 days +13:46:19.004000   \n",
      "\n",
      "   days  count  \n",
      "0     0    1.0  \n",
      "1     0    1.0  \n",
      "2     0    1.0  \n",
      "3     0    1.0  \n",
      "4     0    1.0  \n",
      "5     0    1.0  \n",
      "6     0    1.0  \n",
      "7     0    1.0  \n",
      "8     0    1.0  \n",
      "9     0    1.0  \n",
      "computed\n",
      "   session_id  item_id                    date                      diff  \\\n",
      "0      929236     3732 2021-05-05 14:15:07.278  -5 days +09:44:52.722000   \n",
      "1      984653     4579 2021-05-27 10:24:05.043 -27 days +13:35:54.957000   \n",
      "2      998452     1605 2021-05-31 13:44:52.368 -31 days +10:15:07.632000   \n",
      "3      928718      806 2021-05-05 10:11:06.926  -5 days +13:48:53.074000   \n",
      "4      980028     4503 2021-05-25 16:24:30.224 -25 days +07:35:29.776000   \n",
      "5      970090     2620 2021-05-21 18:12:17.106 -21 days +05:47:42.894000   \n",
      "6      987395     1972 2021-05-28 08:35:35.820 -28 days +15:24:24.180000   \n",
      "7      952246     2725 2021-05-14 19:53:25.760 -14 days +04:06:34.240000   \n",
      "8      951522     1790 2021-05-14 17:48:41.203 -14 days +06:11:18.797000   \n",
      "9      961516     2483 2021-05-18 13:16:44.633 -18 days +10:43:15.367000   \n",
      "\n",
      "   days  count  \n",
      "0     0    1.0  \n",
      "1     0    1.0  \n",
      "2     0    1.0  \n",
      "3     0    1.0  \n",
      "4     0    1.0  \n",
      "5     0    1.0  \n",
      "6     0    1.0  \n",
      "7     0    1.0  \n",
      "8     0    1.0  \n",
      "9     0    1.0  \n",
      "computed\n"
     ]
    }
   ],
   "source": [
    "train_sessions_seen = get_URM_temporal_decay()\n",
    "train_bought = get_URM_temporal_decay(\"train_purchases_train_split_mapped.csv\")\n",
    "\n",
    "valid_sessions_seen= get_URM_temporal_decay(\"train_sessions_valid_split_mapped.csv\")\n",
    "valid_bought = get_URM_temporal_decay(\"train_purchases_valid_split_mapped.csv\")\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_train_seen.npz\"), train_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_train_bought.npz\"), train_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_valid_seen.npz\"), valid_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_valid_bought.npz\"), valid_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_train_full.npz\"), train_sessions_seen+train_bought)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WT_valid_full.npz\"), valid_sessions_seen+valid_bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                    date                     diff  days  \\\n",
      "0      663204     9769 2020-12-18 21:25:00.373 164 days 02:34:59.627000   164   \n",
      "1      663204     9769 2020-12-18 21:19:48.093 164 days 02:40:11.907000   164   \n",
      "2       85375    12783 2020-03-13 19:35:27.136 444 days 04:24:32.864000   444   \n",
      "3      374472    14116 2020-08-26 19:18:30.833 278 days 04:41:29.167000   278   \n",
      "4      374472     6166 2020-08-26 19:16:31.211 278 days 04:43:28.789000   278   \n",
      "5      374472     6924 2020-08-26 19:15:47.232 278 days 04:44:12.768000   278   \n",
      "6      526578     4546 2020-11-02 16:31:18.543 210 days 07:28:41.457000   210   \n",
      "7      526578     8092 2020-11-02 16:34:33.794 210 days 07:25:26.206000   210   \n",
      "8      526578    17752 2020-11-02 16:43:04.022 210 days 07:16:55.978000   210   \n",
      "9      526578    14975 2020-11-02 16:42:02.287 210 days 07:17:57.713000   210   \n",
      "\n",
      "          count  \n",
      "0  4.225293e-03  \n",
      "1  4.225293e-03  \n",
      "2  3.736299e-07  \n",
      "3  9.452307e-05  \n",
      "4  9.452307e-05  \n",
      "5  9.452307e-05  \n",
      "6  9.118820e-04  \n",
      "7  9.118820e-04  \n",
      "8  9.118820e-04  \n",
      "9  9.118820e-04  \n",
      "computed\n",
      "   session_id  item_id                    date                     diff  days  \\\n",
      "0      663204    12492 2020-12-18 21:26:47.986 164 days 02:33:12.014000   164   \n",
      "1       85375     3299 2020-03-13 19:36:15.507 444 days 04:23:44.493000   444   \n",
      "2      374472    17411 2020-08-26 19:20:32.049 278 days 04:39:27.951000   278   \n",
      "3      526578    11229 2020-11-02 17:16:45.920 210 days 06:43:14.080000   210   \n",
      "4       66630    11568 2020-02-26 18:27:44.114 460 days 05:32:15.886000   460   \n",
      "5      192688    18172 2020-05-18 12:52:09.764 378 days 11:07:50.236000   378   \n",
      "6      895749     1512 2021-04-20 19:46:42.594  41 days 04:13:17.406000    41   \n",
      "7      257246    12205 2020-06-21 10:33:22.535 344 days 13:26:37.465000   344   \n",
      "8      789144     2124 2021-03-01 15:17:04.264  91 days 08:42:55.736000    91   \n",
      "9      580394     6925 2020-11-27 20:46:08.951 185 days 03:13:51.049000   185   \n",
      "\n",
      "          count  \n",
      "0  4.225293e-03  \n",
      "1  3.736299e-07  \n",
      "2  9.452307e-05  \n",
      "3  9.118820e-04  \n",
      "4  2.191886e-07  \n",
      "5  3.372015e-06  \n",
      "6  2.549554e-01  \n",
      "7  1.047345e-05  \n",
      "8  4.815485e-02  \n",
      "9  2.098218e-03  \n",
      "computed\n",
      "   session_id  item_id                    date                    diff  days  \\\n",
      "0      929236      417 2021-05-05 13:19:15.147 26 days 10:40:44.853000    26   \n",
      "1      929236     3054 2021-05-05 14:13:21.645 26 days 09:46:38.355000    26   \n",
      "2      929236     2780 2021-05-05 13:19:54.211 26 days 10:40:05.789000    26   \n",
      "3      929236    14829 2021-05-05 13:18:49.495 26 days 10:41:10.505000    26   \n",
      "4      929236     3746 2021-05-05 14:03:43.401 26 days 09:56:16.599000    26   \n",
      "5      929236     1139 2021-05-05 13:18:20.994 26 days 10:41:39.006000    26   \n",
      "6      984653     2950 2021-05-27 10:14:06.491  4 days 13:45:53.509000     4   \n",
      "7      984653     3491 2021-05-27 10:14:01.136  4 days 13:45:58.864000     4   \n",
      "8      984653     2821 2021-05-27 10:13:55.930  4 days 13:46:04.070000     4   \n",
      "9      984653     3491 2021-05-27 10:13:40.996  4 days 13:46:19.004000     4   \n",
      "\n",
      "      count  \n",
      "0  0.420350  \n",
      "1  0.420350  \n",
      "2  0.420350  \n",
      "3  0.420350  \n",
      "4  0.420350  \n",
      "5  0.420350  \n",
      "6  0.875173  \n",
      "7  0.875173  \n",
      "8  0.875173  \n",
      "9  0.875173  \n",
      "computed\n",
      "   session_id  item_id                    date                    diff  days  \\\n",
      "0      929236     3732 2021-05-05 14:15:07.278 26 days 09:44:52.722000    26   \n",
      "1      984653     4579 2021-05-27 10:24:05.043  4 days 13:35:54.957000     4   \n",
      "2      998452     1605 2021-05-31 13:44:52.368  0 days 10:15:07.632000     0   \n",
      "3      928718      806 2021-05-05 10:11:06.926 26 days 13:48:53.074000    26   \n",
      "4      980028     4503 2021-05-25 16:24:30.224  6 days 07:35:29.776000     6   \n",
      "5      970090     2620 2021-05-21 18:12:17.106 10 days 05:47:42.894000    10   \n",
      "6      987395     1972 2021-05-28 08:35:35.820  3 days 15:24:24.180000     3   \n",
      "7      952246     2725 2021-05-14 19:53:25.760 17 days 04:06:34.240000    17   \n",
      "8      951522     1790 2021-05-14 17:48:41.203 17 days 06:11:18.797000    17   \n",
      "9      961516     2483 2021-05-18 13:16:44.633 13 days 10:43:15.367000    13   \n",
      "\n",
      "      count  \n",
      "0  0.420350  \n",
      "1  0.875173  \n",
      "2  1.000000  \n",
      "3  0.420350  \n",
      "4  0.818731  \n",
      "5  0.716531  \n",
      "6  0.904837  \n",
      "7  0.567414  \n",
      "8  0.567414  \n",
      "9  0.648344  \n",
      "computed\n"
     ]
    }
   ],
   "source": [
    "train_sessions_seen = get_URM_temporal_decay(last_date=datetime.strptime(\"01/06/21 00:00:00\", '%d/%m/%y %H:%M:%S'))\n",
    "train_bought = get_URM_temporal_decay(\"train_purchases_train_split_mapped.csv\",last_date=datetime.strptime(\"01/06/21 00:00:00\", '%d/%m/%y %H:%M:%S'))\n",
    "\n",
    "valid_sessions_seen= get_URM_temporal_decay(\"train_sessions_valid_split_mapped.csv\",last_date=datetime.strptime(\"01/06/21 00:00:00\", '%d/%m/%y %H:%M:%S'))\n",
    "valid_bought = get_URM_temporal_decay(\"train_purchases_valid_split_mapped.csv\",last_date=datetime.strptime(\"01/06/21 00:00:00\", '%d/%m/%y %H:%M:%S'))\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_train_seen.npz\"), train_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_train_bought.npz\"), train_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_valid_seen.npz\"), valid_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_valid_bought.npz\"), valid_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_train_full.npz\"), train_sessions_seen+train_bought)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WV_valid_full.npz\"), valid_sessions_seen+valid_bought)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM_temporal_decay_within_session(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False,temperature=5,seen=False):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    df_URM[\"idx\"] = df_URM.index\n",
    "\n",
    "    temp=df_URM.groupby([\"session_id\"])[\"idx\"].max().reset_index()\n",
    "    \n",
    "    temp.rename(columns={\"idx\":\"idx_max\"},inplace=True)\n",
    "    df_URM=df_URM.merge(temp,on=\"session_id\",how=\"left\")\n",
    "    df_URM[\"idx\"]=df_URM[\"idx_max\"]-df_URM[\"idx\"] + 1 if seen else 0\n",
    "    df_URM[\"count\"] = df_URM[\"idx\"].apply(lambda x: np.exp(-x/temperature))\n",
    "    print(df_URM.head(10))\n",
    "\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)),shape=(1000000,23692))\n",
    "\n",
    "    print(\"computed\")\n",
    "\n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                    date  idx  idx_max  count\n",
      "0      663204     9769 2020-12-18 21:25:00.373    0        1    1.0\n",
      "1      663204     9769 2020-12-18 21:19:48.093    0        1    1.0\n",
      "2       85375    12783 2020-03-13 19:35:27.136    0        2    1.0\n",
      "3      374472    14116 2020-08-26 19:18:30.833    0        5    1.0\n",
      "4      374472     6166 2020-08-26 19:16:31.211    0        5    1.0\n",
      "5      374472     6924 2020-08-26 19:15:47.232    0        5    1.0\n",
      "6      526578     4546 2020-11-02 16:31:18.543    0       22    1.0\n",
      "7      526578     8092 2020-11-02 16:34:33.794    0       22    1.0\n",
      "8      526578    17752 2020-11-02 16:43:04.022    0       22    1.0\n",
      "9      526578    14975 2020-11-02 16:42:02.287    0       22    1.0\n",
      "computed\n",
      "   session_id  item_id                    date  idx  idx_max  count\n",
      "0      663204    12492 2020-12-18 21:26:47.986    0        0    1.0\n",
      "1       85375     3299 2020-03-13 19:36:15.507    0        1    1.0\n",
      "2      374472    17411 2020-08-26 19:20:32.049    0        2    1.0\n",
      "3      526578    11229 2020-11-02 17:16:45.920    0        3    1.0\n",
      "4       66630    11568 2020-02-26 18:27:44.114    0        4    1.0\n",
      "5      192688    18172 2020-05-18 12:52:09.764    0        5    1.0\n",
      "6      895749     1512 2021-04-20 19:46:42.594    0        6    1.0\n",
      "7      257246    12205 2020-06-21 10:33:22.535    0        7    1.0\n",
      "8      789144     2124 2021-03-01 15:17:04.264    0        8    1.0\n",
      "9      580394     6925 2020-11-27 20:46:08.951    0        9    1.0\n",
      "computed\n",
      "   session_id  item_id                    date  idx  idx_max  count\n",
      "0      929236      417 2021-05-05 13:19:15.147    0        5    1.0\n",
      "1      929236     3054 2021-05-05 14:13:21.645    0        5    1.0\n",
      "2      929236     2780 2021-05-05 13:19:54.211    0        5    1.0\n",
      "3      929236    14829 2021-05-05 13:18:49.495    0        5    1.0\n",
      "4      929236     3746 2021-05-05 14:03:43.401    0        5    1.0\n",
      "5      929236     1139 2021-05-05 13:18:20.994    0        5    1.0\n",
      "6      984653     2950 2021-05-27 10:14:06.491    0       13    1.0\n",
      "7      984653     3491 2021-05-27 10:14:01.136    0       13    1.0\n",
      "8      984653     2821 2021-05-27 10:13:55.930    0       13    1.0\n",
      "9      984653     3491 2021-05-27 10:13:40.996    0       13    1.0\n",
      "computed\n",
      "   session_id  item_id                    date  idx  idx_max  count\n",
      "0      929236     3732 2021-05-05 14:15:07.278    0        0    1.0\n",
      "1      984653     4579 2021-05-27 10:24:05.043    0        1    1.0\n",
      "2      998452     1605 2021-05-31 13:44:52.368    0        2    1.0\n",
      "3      928718      806 2021-05-05 10:11:06.926    0        3    1.0\n",
      "4      980028     4503 2021-05-25 16:24:30.224    0        4    1.0\n",
      "5      970090     2620 2021-05-21 18:12:17.106    0        5    1.0\n",
      "6      987395     1972 2021-05-28 08:35:35.820    0        6    1.0\n",
      "7      952246     2725 2021-05-14 19:53:25.760    0        7    1.0\n",
      "8      951522     1790 2021-05-14 17:48:41.203    0        8    1.0\n",
      "9      961516     2483 2021-05-18 13:16:44.633    0        9    1.0\n",
      "computed\n"
     ]
    }
   ],
   "source": [
    "train_sessions_seen = get_URM_temporal_decay_within_session()\n",
    "train_bought = get_URM_temporal_decay_within_session(\"train_purchases_train_split_mapped.csv\")\n",
    "\n",
    "valid_sessions_seen= get_URM_temporal_decay_within_session(\"train_sessions_valid_split_mapped.csv\")\n",
    "valid_bought = get_URM_temporal_decay_within_session(\"train_purchases_valid_split_mapped.csv\")\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_train_seen.npz\"), train_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_train_bought.npz\"), train_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_valid_seen.npz\"), valid_sessions_seen)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_valid_bought.npz\"), valid_bought)\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_train_full.npz\"), train_sessions_seen+train_bought)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_valid_full.npz\"), valid_sessions_seen+valid_bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions_seen[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_URM_test_temporal_decay_within_session(file='train_sessions_train_split_mapped.csv',files_directory=\"../dataset/processed_data\", normalized=False,weight_decay=False,temperature=5):\n",
    "    df_URM = pd.read_csv(filepath_or_buffer=os.path.join(files_directory, file), sep=',', header=0,\n",
    "                         parse_dates=['date'], \n",
    "                         infer_datetime_format=True)\n",
    "    \n",
    "    \n",
    "    df_URM[\"idx\"] = df_URM.index\n",
    "\n",
    "    temp=df_URM.groupby([\"session_id\"])[\"idx\"].max().reset_index()\n",
    "    \n",
    "    temp.rename(columns={\"idx\":\"idx_max\"},inplace=True)\n",
    "    df_URM=df_URM.merge(temp,on=\"session_id\",how=\"left\")\n",
    "    df_URM[\"idx\"]=df_URM[\"idx_max\"]-df_URM[\"idx\"] + 1 \n",
    "    df_URM[\"count\"] = df_URM[\"idx\"].apply(lambda x: np.exp(-x/temperature))\n",
    "\n",
    "    print(df_URM.head(10))\n",
    "\n",
    "    df_URM = df_URM.groupby([\"session_id\", \"item_id\"])[\"count\"].sum().reset_index()\n",
    "    session_id_list = df_URM['session_id'].values\n",
    "    item_id_list = df_URM['item_id'].values\n",
    "    \n",
    "    if not normalized:\n",
    "        rating_id_list = df_URM['count'].values\n",
    "    else:\n",
    "        rating_id_list = np.ones_like(session_id_list)\n",
    "\n",
    "\n",
    "    URM = sps.csr_matrix((rating_id_list, (session_id_list, item_id_list)))\n",
    "\n",
    "    \n",
    "\n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                    date  idx  idx_max     count\n",
      "0          26     3404 2021-06-16 09:53:54.158    1        0  0.818731\n",
      "1         200     3037 2021-06-25 12:23:40.811    4        4  0.449329\n",
      "2         200     3037 2021-06-25 12:24:36.631    3        4  0.548812\n",
      "3         200     1468 2021-06-25 12:24:41.677    2        4  0.670320\n",
      "4         200      887 2021-06-25 12:24:50.692    1        4  0.818731\n",
      "5         205     1484 2021-06-11 00:28:07.058    1        5  0.818731\n",
      "6         495     1250 2021-06-14 22:13:06.741    1        6  0.818731\n",
      "7         521     4673 2021-06-19 13:50:03.090    1        7  0.818731\n",
      "8         587     3945 2021-06-01 16:43:22.800    1        8  0.818731\n",
      "9         721     2464 2021-06-19 18:46:57.263    1        9  0.818731\n",
      "   session_id  item_id                    date  idx  idx_max     count\n",
      "0          61     4785 2021-06-01 08:12:39.664    1        0  0.818731\n",
      "1          96     2107 2021-06-19 17:48:05.227    5        5  0.367879\n",
      "2          96     3251 2021-06-19 17:49:08.589    4        5  0.449329\n",
      "3          96      884 2021-06-19 17:49:15.838    3        5  0.548812\n",
      "4          96       89 2021-06-19 17:49:20.880    2        5  0.670320\n",
      "5          96     1252 2021-06-19 17:56:21.317    1        5  0.818731\n",
      "6         185     3133 2021-06-07 15:53:21.640    5       10  0.367879\n",
      "7         185     3767 2021-06-07 15:53:29.483    4       10  0.449329\n",
      "8         185     3767 2021-06-07 15:53:53.069    3       10  0.548812\n",
      "9         185     3133 2021-06-07 15:54:07.491    2       10  0.670320\n"
     ]
    }
   ],
   "source": [
    "test_leaderboard = get_URM_test_temporal_decay_within_session(file=\"test_leaderboard_sessions_mapped.csv\")\n",
    "\n",
    "test_final = get_URM_test_temporal_decay_within_session(file=\"test_final_sessions_mapped.csv\")\n",
    "\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_test_leaderboard.npz\"), test_leaderboard)\n",
    "sps.save_npz(os.path.join(processed_data, \"URM_WW_test_final.npz\"), test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.02791218733398"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_leaderboard[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__==\"2.8.2\",\"tf_version is wrong\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('sub_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61f38fddaed46afda7c40a5798d4631266e18af1d335aa6f772dc3ed9b8ab549"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
